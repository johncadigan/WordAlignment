spark lines:

import org.apache.spark.SparkContext
import org.apache.spark.SparkContext._
import org.apache.spark.SparkConf

import scala.io.Source
import java.io.BufferedWriter
import java.io.BufferedReader
import java.io.File
import java.io.FileWriter
import java.io.FileReader

import scala.collection.mutable.{Map => MMap}
import scala.collection.mutable.MutableList
import scala.collection.mutable.HashMap

val fs = sc.textFile("hans2000.f")
val source = fs.map(x=>x.stripLineEnd.split("\\s+")).collect()
val ft = sc.textFile("hans2000.e")
val target = ft.map(x=>x.stripLineEnd.split("\\s+")).collect()
val null_value = "NULL#!@"

val source_words = source.par.flatMap(x=>x).toSet.toArray.sorted
val source_map = source_words.zipWithIndex.toMap
val width = source_map.size
val target_words = (target.flatMap(x=>x.filter(y=>y!=null_value)).toSet.toArray.sorted)
val target_map = target_words.zipWithIndex.toMap    
val hash = target_map.size
val source_sents = source.map(x=>x.map(y=>source_map(y)))  
val target_sents = target.map(x=>x.map(y=>target_map(y)))    
val combos =  source_sents.zip(target_sents).par.flatMap(x=>x._1.flatMap(y=>(x._2).map(z=>(y,z)))).seq.toSet.toArray     
val possible_translations = combos.groupBy(x=>x._1).map(x=>(x._1, x._2.size.toDouble))
val combined = sc.parallelize(source_sents.zip(target_sents))

val probs = val probs = Array.ofDim[Double](source_map.size*(target_map.size+1))
combos.foreach(x=>probs(x._1)(x._2)=1.0/possible_translations(x._1))
var probs = HashMap(combos.map(x=>(x._2*width+x._1.toLong,1.0/possible_translations(x._1))).seq.toSeq: _*)


  def helper(pair: Tuple2[Array[Int],Array[Int]], prob: Array[Double]): Array[Tuple2[Int,Double]] = {
          
          val sSize = pair._1.size
          val tSize = pair._2.size
          var res = Array.fill(sSize*tSize * 2)((0,0.0))
          var index = 0;
          var deltas = MMap[Int, Double]().withDefaultValue(0.0)
          for(j <-0 to tSize-1){
               var delta = 0.0
            for(i <-0 to sSize-1){
               delta += prob(pair._2(j)*width+pair._1(i))
            }
            for(i <-0 to sSize-1){
                val ef = pair._2(j)*width+pair._1(i)
                val f =  width*hash+pair._1(i)%width
                val pef = prob(ef)/delta
                res(index) = (ef, pef)
                res(index+1) = (f, pef)
                index+=2
            }
          }
          return res;
  }

class fo(w: Int, h: Int, p: HashMap[Long, Double] ) extends Serializable {
        val width = w;
        val hash = h;
        val prob = p;     
	def helper(pair: Tuple2[Array[Int],Array[Int]]): Array[Tuple2[Long,Double]] = {
          
          val sSize = pair._1.size
          val tSize = pair._2.size
          var res = Array.fill(sSize*tSize * 2)((0.toLong,0.0))
          var index = 0;
          var deltas = MMap[Long, Double]().withDefaultValue(0.0)
          for(j <-0 to tSize-1){
               var delta = 0.0
            for(i <-0 to sSize-1){
               delta += prob(pair._2(j)*width+pair._1(i))
            }
            for(i <-0 to sSize-1){
                val ef = pair._2(j)*width+pair._1(i)
                val f =  pair._2(j)*width+hash
                val pef = prob(ef)/delta
                res(index) = (ef, pef)
                res(index+1) = (f, pef)
                index+=2
            }
          }
          return res;
  } 
}

